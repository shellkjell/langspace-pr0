# LangSpace Advanced Example: Autonomous Research Agent
# A self-directed AI system that explores topics, synthesizes findings,
# manages citations, and produces comprehensive research reports.
#
# This example demonstrates:
# - Iterative refinement loops
# - Multi-source information gathering
# - Citation and reference management
# - Quality evaluation and improvement
# - Parallel sub-topic exploration

# ============================================================================
# CONFIGURATION
# ============================================================================

config {
  default_model: "claude-sonnet-4-20250514"

  providers: {
    anthropic: {
      api_key: env("ANTHROPIC_API_KEY")
      max_tokens: 8192
    }
  }

  # Research-specific settings
  research: {
    max_iterations: 5
    min_quality_score: 8
    max_sources_per_topic: 10
    citation_style: "APA"
  }
}

# ============================================================================
# KNOWLEDGE MANAGEMENT FILES
# ============================================================================

file "research-methodology" {
  contents: ```
    # Research Methodology Guidelines

    ## Source Evaluation Criteria
    1. **Authority**: Is the author/publisher credible?
    2. **Accuracy**: Can claims be verified?
    3. **Currency**: Is the information up-to-date?
    4. **Relevance**: Does it address the research question?
    5. **Purpose**: Is it objective or biased?

    ## Information Synthesis Rules
    - Cross-reference claims across multiple sources
    - Note contradictions and different perspectives
    - Prioritize primary sources over secondary
    - Document methodology limitations

    ## Citation Requirements
    - All factual claims must be cited
    - Use direct quotes sparingly, prefer paraphrasing
    - Include page numbers where applicable
    - Note access dates for online sources
  ```
}

file "report-template" {
  contents: ```
    # {{title}}

    **Research Date**: {{date}}
    **Primary Question**: {{question}}
    **Confidence Level**: {{confidence}}/10

    ## Executive Summary
    {{executive_summary}}

    ## Background
    {{background}}

    ## Key Findings
    {{findings}}

    ## Analysis
    {{analysis}}

    ## Implications
    {{implications}}

    ## Limitations
    {{limitations}}

    ## Future Research Directions
    {{future_directions}}

    ## References
    {{references}}

    ---
    *Generated by LangSpace Research Agent v1.0*
  ```
}

# ============================================================================
# TOOLS
# ============================================================================

mcp "web" {
  transport: "stdio"
  command: "npx"
  args: ["-y", "@anthropic/mcp-web"]
}

mcp "filesystem" {
  transport: "stdio"
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-filesystem", "./research"]
}

tool "search_web" {
  description: "Search the web for information on a topic"

  parameters: {
    query: string required "Search query"
    num_results: number optional 10 "Number of results to return"
    date_filter: string optional "any" "Filter by date: day, week, month, year, any"
  }

  handler: http {
    method: "GET"
    url: "https://api.search.brave.com/res/v1/web/search"
    query: {
      q: params.query
      count: params.num_results
      freshness: params.date_filter
    }
    headers: {
      "X-Subscription-Token": env("BRAVE_API_KEY")
    }
  }
}

tool "fetch_page" {
  description: "Fetch and extract content from a web page"

  parameters: {
    url: string required "URL to fetch"
    extract_type: string optional "main" "Type: main, full, summary"
  }

  handler: mcp("web").fetch_page
}

tool "store_citation" {
  description: "Store a citation in the research database"

  parameters: {
    source_url: string required
    title: string required
    authors: array optional
    date: string optional
    content_summary: string required
    relevance_score: number required "1-10"
  }

  handler: builtin("research.store_citation")
}

# Script for efficient batch web research
script "batch-research" {
  language: "python"
  runtime: "python3"

  capabilities: [network, filesystem.write]

  parameters: {
    queries: array required "List of search queries"
    output_dir: string optional "./research/sources"
  }

  code: ```python
    import json
    import urllib.request
    import os
    from datetime import datetime

    os.makedirs(output_dir, exist_ok=True)
    results = []

    for i, query in enumerate(json.loads(queries)):
        try:
            # Simulated search - in production, use actual API
            print(f"[{i+1}/{len(queries)}] Searching: {query}")

            result = {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "sources": []  # Would contain actual search results
            }
            results.append(result)

            # Save individual result
            filename = f"{output_dir}/search_{i+1}.json"
            with open(filename, 'w') as f:
                json.dump(result, f, indent=2)

        except Exception as e:
            print(f"  Error: {e}")

    # Summary
    print(f"\nCompleted {len(results)} searches")
    print(f"Results saved to {output_dir}")
  ```

  timeout: "5m"
}

# ============================================================================
# SPECIALIZED AGENTS
# ============================================================================

agent "research-planner" {
  model: "claude-sonnet-4-20250514"
  temperature: 0.4

  instruction: ```
    You are a research planning specialist. Given a research question or topic,
    you decompose it into specific, searchable sub-questions.

    Your responsibilities:
    1. Identify the core question and its dimensions
    2. Break down into 3-7 focused sub-questions
    3. Prioritize sub-questions by importance
    4. Identify potential source types for each
    5. Flag any ambiguities that need clarification

    Output Format (JSON):
    {
      "main_question": "...",
      "clarified_scope": "...",
      "sub_questions": [
        {
          "id": 1,
          "question": "...",
          "priority": "high|medium|low",
          "source_types": ["academic", "news", "official"],
          "search_queries": ["query1", "query2"]
        }
      ],
      "research_strategy": "...",
      "estimated_depth": "shallow|moderate|deep"
    }
  ```
}

agent "source-evaluator" {
  model: "claude-sonnet-4-20250514"
  temperature: 0.2

  instruction: file("research-methodology")

  tools: [
    tool("fetch_page"),
    tool("store_citation")
  ]
}

agent "information-synthesizer" {
  model: "claude-sonnet-4-20250514"
  temperature: 0.3

  instruction: ```
    You synthesize information from multiple sources into coherent findings.

    Your process:
    1. Identify common themes across sources
    2. Note areas of consensus and disagreement
    3. Evaluate the strength of evidence for claims
    4. Construct a logical narrative
    5. Highlight gaps in the available information

    Critical rules:
    - Never fabricate information or sources
    - Clearly distinguish facts from interpretations
    - Acknowledge uncertainty where it exists
    - Maintain source attribution throughout

    Output comprehensive, well-structured findings with inline citations.
  ```
}

agent "research-critic" {
  model: "claude-sonnet-4-20250514"
  temperature: 0.5

  instruction: ```
    You are a rigorous research quality evaluator. Your job is to identify
    weaknesses, gaps, and areas for improvement in research outputs.

    Evaluate on these dimensions (1-10 each):
    1. Comprehensiveness: Does it cover all important aspects?
    2. Accuracy: Are claims well-supported and verifiable?
    3. Balance: Are multiple perspectives represented?
    4. Clarity: Is it well-organized and understandable?
    5. Depth: Does it go beyond surface-level information?
    6. Originality: Does it offer valuable insights?
    7. Practical Value: Is it actionable/useful?

    Output Format (JSON):
    {
      "overall_score": 7.5,
      "dimension_scores": {...},
      "strengths": ["..."],
      "weaknesses": ["..."],
      "gaps": ["..."],
      "improvement_suggestions": ["..."],
      "additional_queries": ["..."]  // New searches to fill gaps
    }
  ```
}

agent "report-writer" {
  model: "claude-sonnet-4-20250514"
  temperature: 0.4

  instruction: ```
    You are an expert research report writer. You transform research findings
    into polished, professional reports.

    Writing style:
    - Clear and accessible, but not dumbed down
    - Logical flow with smooth transitions
    - Active voice where possible
    - Specific rather than vague

    Structural requirements:
    - Executive summary (1-2 paragraphs, key takeaways)
    - Organized sections with clear headings
    - Supporting evidence with citations
    - Honest discussion of limitations
    - Forward-looking implications

    Use the provided template as a starting point but adapt as needed
    for the specific content and audience.
  ```

  context: [file("report-template")]
}

# ============================================================================
# RESEARCH PIPELINE
# ============================================================================

pipeline "deep-research" {
  # Step 1: Plan the research
  step "plan" {
    use: agent("research-planner")
    input: $input

    instruction: "Create a comprehensive research plan for this topic."
  }

  # Step 2: Gather sources in parallel for each sub-question
  step "gather" {
    # Execute batch research script for efficiency
    execute: script("batch-research") {
      queries: step("plan").output.sub_questions.map(q => q.search_queries).flatten()
    }
  }

  # Step 3: Evaluate and filter sources
  step "evaluate" {
    use: agent("source-evaluator")
    input: step("gather").output

    instruction: ```
      Evaluate each source for credibility and relevance.
      Store high-quality sources as citations.
      Return a curated list of the most valuable sources.
    ```
  }

  # Step 4: Synthesize findings
  step "synthesize" {
    use: agent("information-synthesizer")

    input: step("evaluate").output
    context: [
      $input,  # Original question
      step("plan").output  # Research plan for structure
    ]
  }

  # Step 5: Critical review loop
  loop max: 3 {
    step "critique" {
      use: agent("research-critic")
      input: $current_synthesis

      instruction: "Rigorously evaluate this research synthesis."
    }

    # Exit if quality threshold met
    break_if: step("critique").output.overall_score >= 8

    # Fill gaps with additional research
    step "fill-gaps" {
      execute: script("batch-research") {
        queries: step("critique").output.additional_queries
      }
    }

    # Re-synthesize with new information
    step "improve" {
      use: agent("information-synthesizer")

      input: [
        $current_synthesis,
        step("fill-gaps").output
      ]

      context: [
        step("critique").output.improvement_suggestions
      ]
    }

    set $current_synthesis: step("improve").output
  }

  # Step 6: Generate final report
  step "report" {
    use: agent("report-writer")

    input: $current_synthesis

    context: [
      $input,
      step("plan").output,
      step("critique").output
    ]
  }

  output: step("report").output
}

# Quick research for simpler queries
pipeline "quick-research" {
  step "search" {
    tools: [tool("search_web")]
    input: $input

    instruction: "Search for relevant, recent information on this topic."
  }

  step "synthesize" {
    use: agent("information-synthesizer")
    input: step("search").output
    context: [$input]
  }

  output: step("synthesize").output
}

# ============================================================================
# TRIGGERS
# ============================================================================

trigger "research-request" {
  event: slack.message {
    channel: "#research-requests"
    contains: "@research-bot"
  }

  run: pipeline("deep-research") {
    input: slack.message.text
  }

  on_complete: {
    slack.post_message(
      channel: slack.message.channel,
      text: output,
      thread_ts: slack.message.ts
    )
  }

  on_error: {
    slack.post_message(
      channel: slack.message.channel,
      text: "Research failed: " + error.message,
      thread_ts: slack.message.ts
    )
  }
}

trigger "scheduled-research" {
  event: schedule("0 6 * * 1")  # Monday 6 AM

  run: pipeline("deep-research") {
    input: file("research/weekly-topics.txt")
  }

  on_complete: {
    email.send(
      to: env("RESEARCH_TEAM_EMAIL"),
      subject: "Weekly Research Report",
      body: output
    )
    mcp("filesystem").write_file(
      path: "research/reports/weekly-" + date("YYYY-MM-DD") + ".md",
      content: output
    )
  }
}

# ============================================================================
# CLI ENTRYPOINTS
# ============================================================================

# Deep research: langspace run research.ls research "topic"
intent "research" {
  params: {
    topic: string required "Research topic or question"
    depth: string optional "deep" "Research depth: quick, deep"
  }

  run: {
    if params.depth == "quick" {
      pipeline("quick-research") { input: params.topic }
    } else {
      pipeline("deep-research") { input: params.topic }
    }
  }

  output: file("research/output/{{timestamp}}-report.md")
}

# Continue/improve existing research
intent "improve-research" {
  params: {
    report_path: string required "Path to existing research report"
    feedback: string optional "Specific areas to improve"
  }

  use: agent("research-critic")
  input: file(params.report_path)
  context: [params.feedback]

  # Re-run improvement loop
  then: pipeline("deep-research") {
    input: output.improvement_suggestions
  }
}

# Search only (no synthesis)
intent "search" {
  params: {
    query: string required "Search query"
    num_results: number optional 20
  }

  tools: [tool("search_web")]
  input: params.query

  output: stdout
}
